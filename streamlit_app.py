import streamlit as st
from dotenv import load_dotenv
import os
import time
import numpy as np
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnablePassthrough, RunnableParallel

# Configuration de la page avec style personnalis√©
st.set_page_config(page_title="CSRD/ESRS Assistant Adamantia", layout="wide", page_icon="üìÑ")

# Style CSS personnalis√©
st.markdown("""
<style>
.stTextInput > div > div > input {
    border: 2px solid #3498db;
    border-radius: 10px;
    padding: 12px;
    font-size: 16px;
}
.response-box {
    background-color: #f0f4f8;
    border-radius: 15px;
    padding: 20px;
    margin-top: 20px;
}
.question-section {
    background-color: #e6f2ff;
    border-radius: 10px;
    padding: 15px;
    margin-bottom: 20px;
}
</style>
""", unsafe_allow_html=True)

def calculate_cosine_similarity(vec1, vec2):
    """Calcule la similarit√© cosinus entre deux vecteurs."""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)

def check_response_relevance(question, response, retrieved_docs, threshold=0.5):
    """
    V√©rifie la pertinence de la r√©ponse par rapport aux documents et √† la question.
    
    Args:
        question (str): La question pos√©e
        response (str): La r√©ponse g√©n√©r√©e
        retrieved_docs (list): Documents r√©cup√©r√©s
        threshold (float): Seuil de similarit√©
    
    Returns:
        bool: Indique si la r√©ponse est pertinente
    """
    try:
        embeddings = OpenAIEmbeddings()
        
        # Embedding de la question
        question_embedding = embeddings.embed_query(question)
        
        # Embedding de la r√©ponse
        response_embedding = embeddings.embed_query(response)
        
        # Embedding des documents
        doc_embeddings = [embeddings.embed_query(doc.page_content) for doc in retrieved_docs]
        
        # Calcul des similarit√©s
        response_doc_similarities = [calculate_cosine_similarity(response_embedding, doc_emb) 
                                     for doc_emb in doc_embeddings]
        
        # Moyenne des similarit√©s
        avg_similarity = np.mean(response_doc_similarities)
        
        return avg_similarity >= threshold
    
    except Exception as e:
        st.error(f"Erreur lors de la v√©rification de pertinence : {e}")
        return False

# Reste de votre code d'initialisation identique
def initialize_application():
    load_dotenv()
    API_KEY = os.getenv('OPENAI_API_KEY')

    # Initialisation du mod√®le
    model = ChatOpenAI(api_key=API_KEY, model='gpt-3.5-turbo', temperature=0.2)

    # Chargement des documents
    documents = []
    pdf_folder = "Documentation_CSRD"
    for file_name in os.listdir(pdf_folder):
        if file_name.endswith(".pdf"):
            file_path = os.path.join(pdf_folder, file_name)
            loader = PyPDFLoader(file_path)
            documents.extend(loader.load())

    # Pr√©paration des documents
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,
        chunk_overlap=200,
        separators=["\n\n", "\n", ". ", " ", ""],
    )
    pages = splitter.split_documents(documents)

    # Base vectorielle
    try:
        vector_storage = FAISS.load_local("faiss_index", OpenAIEmbeddings())
    except:
        vector_storage = FAISS.from_documents(pages, OpenAIEmbeddings())
        vector_storage.save_local("faiss_index")

    # Configuration du retriever
    retriever = vector_storage.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 5}
    )

    # Template de prompt
    question_template = """
    Tu es un expert en r√©glementation CSRD/ESRS. 
    Contexte: {context}
    Question: {question}
    
    R√©ponds de mani√®re professionnelle et pr√©cise. 
    Si tu ne peux pas r√©pondre avec certitude √† partir du contexte, dis-le clairement.
    """

    prompt = PromptTemplate.from_template(template=question_template)
    
    # Cha√Æne de traitement
    def custom_invoke(input_question):
        # R√©cup√©ration des documents
        retrieved_docs = retriever.get_relevant_documents(input_question)
        
        # Pr√©paration du contexte
        context = "\n\n".join([doc.page_content for doc in retrieved_docs])
        
        # G√©n√©ration de la r√©ponse
        response = model.invoke(
            prompt.format(
                context=context, 
                question=input_question
            )
        ).content
        
        # V√©rification de pertinence
        if not check_response_relevance(input_question, response, retrieved_docs):
            return "Je suis d√©sol√©, mais je n'ai pas trouv√© d'informations suffisamment pr√©cises dans mes documents pour r√©pondre √† cette question avec certitude."
        
        return response

    return custom_invoke

# Configuration principale
def main():
    st.title("üîç Assistant CSRD/ESRS")
    
    # Initialisation de la cha√Æne de traitement
    if 'chain' not in st.session_state:
        st.session_state.chain = initialize_application()
    
    # Section de question stylis√©e
    st.markdown("<div class='question-section'>", unsafe_allow_html=True)
    question = st.text_input(
        "Posez votre question", 
        placeholder="Par exemple : Quels sont les principaux changements introduits par la CSRD ?",
        help="Formulez votre question sur la r√©glementation CSRD/ESRS"
    )
    st.markdown("</div>", unsafe_allow_html=True)
    
    if question:
        with st.spinner("Analyse en cours..."):
            # G√©n√©ration de la r√©ponse
            response = st.session_state.chain(question)
            
            # Affichage dans un cadre stylis√©
            st.markdown("<div class='response-box'>", unsafe_allow_html=True)
            st.markdown("### üìù Votre Question")
            st.write(question)
            st.markdown("### üí° R√©ponse")
            st.write(response)
            st.markdown("</div>", unsafe_allow_html=True)

# Ex√©cution principale
if __name__ == "__main__":
    main()